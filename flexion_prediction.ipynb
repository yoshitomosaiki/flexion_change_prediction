{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "ROM = pd.read_csv(\"C:/Users/user/data.csv\") \n",
    "X = np.array(ROM.drop('ROM_worsing',1))\n",
    "y = np.array(ROM['ROM_worsing'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import sqrt\n",
    "stkf = StratifiedKFold(n_splits=5)\n",
    "mmscaler = preprocessing.MinMaxScaler() \n",
    "select7 = RFE(RandomForestClassifier(n_estimators=300), n_features_to_select=7, verbose=1)\n",
    "select6 = RFE(RandomForestClassifier(n_estimators=300), n_features_to_select=6, verbose=1)\n",
    "select5 = RFE(RandomForestClassifier(n_estimators=300), n_features_to_select=5, verbose=1)\n",
    "select4 = RFE(RandomForestClassifier(n_estimators=300), n_features_to_select=4, verbose=1)\n",
    "select3 = RFE(RandomForestClassifier(n_estimators=300), n_features_to_select=3, verbose=1)\n",
    "\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_params = {'C':[0.01,0.1,1,10,100]}\n",
    "log = LogisticRegression(multi_class = 'auto', max_iter=500)\n",
    "\n",
    "# Support vector machine\n",
    "from sklearn.svm import SVC\n",
    "svc_params = {'C':[100,1000], 'gamma':[1,0.1,0.01,0.001]}\n",
    "svc = SVC(kernel='rbf', max_iter=500)\n",
    "\n",
    "# MLP classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_params = {'hidden_layer_sizes':[100,100,100], 'learning_rate_init':[0.1,0.01,0.001]}\n",
    "mlp = MLPClassifier(activation='relu' ,solver='adam', max_iter=500)\n",
    "\n",
    "# Decition tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_params = {'max_depth':[2,3,4,5,10,15], 'min_samples_leaf':[5,10,15], 'min_samples_split':[2,3,4,5]}\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_params = {'n_estimators':[500,800], 'criterion': ['entropy'], 'max_depth':[2,3,4,5,10,15],'bootstrap': ['False','True']}\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "lists=[]\n",
    "for train_index, test_index in stkf.split(X, y):\n",
    "    # Recursive Feature Elimination with random forest\n",
    "    select5.fit(X[train_index], y[train_index])\n",
    "    X_train_sel = select5.transform(X[train_index])\n",
    "    X_test_sel = select5.transform(X[test_index])\n",
    "    \n",
    "    # Logistic regression\n",
    "    gslog = GridSearchCV(log, log_params, cv=stkf) \n",
    "    gslog.fit(X_train_sel, y[train_index])\n",
    "    best = gslog.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    log_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(log_accuracy)\n",
    "    log_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(log_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = log_auc / (2 - log_auc)\n",
    "    Q2 = 2*log_auc**2 / (1 + log_auc)\n",
    "    SE_AUC = sqrt((log_auc*(1 - log_auc) + (N1 - 1)*(Q1 - log_auc**2) + (N2 - 1)*(Q2 - log_auc**2)) / (N1*N2))\n",
    "    lower = log_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = log_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # SVM \n",
    "    gssvc = GridSearchCV(svc, svc_params, cv=stkf)\n",
    "    gssvc.fit(X_train_sel, y[train_index])\n",
    "    best = gssvc.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    svc_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(svc_accuracy)\n",
    "    svc_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(svc_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = svc_auc / (2 - svc_auc)\n",
    "    Q2 = 2*svc_auc**2 / (1 + svc_auc)\n",
    "    SE_AUC = sqrt((svc_auc*(1 - svc_auc) + (N1 - 1)*(Q1 - svc_auc**2) + (N2 - 1)*(Q2 - svc_auc**2)) / (N1*N2))\n",
    "    lower = svc_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = svc_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # MLP classifier\n",
    "    gsmlp = GridSearchCV(mlp, mlp_params, cv=stkf) \n",
    "    gsmlp.fit(X_train_sel, y[train_index])\n",
    "    best = gsmlp.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    mlp_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(mlp_accuracy)\n",
    "    mlp_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(mlp_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = mlp_auc / (2 - mlp_auc)\n",
    "    Q2 = 2*mlp_auc**2 / (1 + mlp_auc)\n",
    "    SE_AUC = sqrt((mlp_auc*(1 - mlp_auc) + (N1 - 1)*(Q1 - mlp_auc**2) + (N2 - 1)*(Q2 - mlp_auc**2)) / (N1*N2))\n",
    "    lower = mlp_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = mlp_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # Decition tree\n",
    "    gstree = GridSearchCV(tree, tree_params, cv=stkf) \n",
    "    gstree.fit(X_train_sel, y[train_index])\n",
    "    best = gstree.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    tree_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(tree_accuracy)\n",
    "    tree_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(tree_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = tree_auc / (2 - tree_auc)\n",
    "    Q2 = 2*tree_auc**2 / (1 + tree_auc)\n",
    "    SE_AUC = sqrt((tree_auc*(1 - tree_auc) + (N1 - 1)*(Q1 - tree_auc**2) + (N2 - 1)*(Q2 - tree_auc**2)) / (N1*N2))\n",
    "    lower = tree_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = tree_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # Five variables\n",
    "    gsforest = GridSearchCV(forest, forest_params, cv=stkf) \n",
    "    gsforest.fit(X_train_sel, y[train_index])\n",
    "    best = gsforest.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    forest_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(forest_accuracy)\n",
    "    forest_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(forest_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = forest_auc / (2 - forest_auc)\n",
    "    Q2 = 2*forest_auc**2 / (1 + forest_auc)\n",
    "    SE_AUC = sqrt((forest_auc*(1 - forest_auc) + (N1 - 1)*(Q1 - forest_auc**2) + (N2 - 1)*(Q2 - forest_auc**2)) / (N1*N2))\n",
    "    lower = forest_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = forest_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # Six variables\n",
    "    select6.fit(X[train_index], y[train_index])\n",
    "    X_train_sel = select6.transform(X[train_index])\n",
    "    X_test_sel = select6.transform(X[test_index])\n",
    "    gsforest = GridSearchCV(forest, forest_params, cv=stkf) \n",
    "    gsforest.fit(X_train_sel, y[train_index])\n",
    "    best = gsforest.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    forest_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(forest_accuracy)\n",
    "    forest_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(forest_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = forest_auc / (2 - forest_auc)\n",
    "    Q2 = 2*forest_auc**2 / (1 + forest_auc)\n",
    "    SE_AUC = sqrt((forest_auc*(1 - forest_auc) + (N1 - 1)*(Q1 - forest_auc**2) + (N2 - 1)*(Q2 - forest_auc**2)) / (N1*N2))\n",
    "    lower = forest_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = forest_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # Seven variables\n",
    "    select7.fit(X[train_index], y[train_index])\n",
    "    X_train_sel = select7.transform(X[train_index])\n",
    "    X_test_sel = select7.transform(X[test_index])\n",
    "    gsforest = GridSearchCV(forest, forest_params, cv=stkf) \n",
    "    gsforest.fit(X_train_sel, y[train_index])\n",
    "    best = gsforest.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    forest_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(forest_accuracy)\n",
    "    forest_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(forest_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = forest_auc / (2 - forest_auc)\n",
    "    Q2 = 2*forest_auc**2 / (1 + forest_auc)\n",
    "    SE_AUC = sqrt((forest_auc*(1 - forest_auc) + (N1 - 1)*(Q1 - forest_auc**2) + (N2 - 1)*(Q2 - forest_auc**2)) / (N1*N2))\n",
    "    lower = forest_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = forest_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # Four variables\n",
    "    select4.fit(X[train_index], y[train_index])\n",
    "    X_train_sel = select4.transform(X[train_index])\n",
    "    X_test_sel = select4.transform(X[test_index])\n",
    "    gsforest = GridSearchCV(forest, forest_params, cv=stkf) \n",
    "    gsforest.fit(X_train_sel, y[train_index])\n",
    "    best = gsforest.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    forest_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(forest_accuracy)\n",
    "    forest_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(forest_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = forest_auc / (2 - forest_auc)\n",
    "    Q2 = 2*forest_auc**2 / (1 + forest_auc)\n",
    "    SE_AUC = sqrt((forest_auc*(1 - forest_auc) + (N1 - 1)*(Q1 - forest_auc**2) + (N2 - 1)*(Q2 - forest_auc**2)) / (N1*N2))\n",
    "    lower = forest_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = forest_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "    \n",
    "    # Three variables\n",
    "    select3.fit(X[train_index], y[train_index])\n",
    "    X_train_sel = select3.transform(X[train_index])\n",
    "    X_test_sel = select3.transform(X[test_index])\n",
    "    gsforest = GridSearchCV(forest, forest_params, cv=stkf) \n",
    "    gsforest.fit(X_train_sel, y[train_index])\n",
    "    best = gsforest.best_estimator_\n",
    "    best_y = best.predict(X_test_sel)\n",
    "    forest_accuracy = accuracy_score(y[test_index], best_y)\n",
    "    lists.append(forest_accuracy)\n",
    "    forest_auc = roc_auc_score(y[test_index], best_y)\n",
    "    lists.append(forest_auc)\n",
    "    N1 = sum(y[test_index] == 1)\n",
    "    N2 = sum(y[test_index] != 1)\n",
    "    Q1 = forest_auc / (2 - forest_auc)\n",
    "    Q2 = 2*forest_auc**2 / (1 + forest_auc)\n",
    "    SE_AUC = sqrt((forest_auc*(1 - forest_auc) + (N1 - 1)*(Q1 - forest_auc**2) + (N2 - 1)*(Q2 - forest_auc**2)) / (N1*N2))\n",
    "    lower = forest_auc - 1.96*SE_AUC\n",
    "    lists.append(lower)\n",
    "    upper = forest_auc + 1.96*SE_AUC\n",
    "    lists.append(upper)\n",
    "lists\n",
    "\n",
    "# Feature importance\n",
    "data=pd.DataFrame(lists)\n",
    "data.to_csv(\"C:/Users/user/data.csv\", encoding = 'shift-jis')\n",
    "lists=[]\n",
    "for train_index, test_index in stkf.split(X, y):\n",
    "    forest.fit(X[train_index], y[train_index])\n",
    "    fi = forest.feature_importances_\n",
    "    lists.append(fi)\n",
    "data=pd.DataFrame(lists)\n",
    "mfi = mmscaler.fit_transform(data.T)\n",
    "mfi = pd.DataFrame(mfi, columns=['a','b','c','d','e'])\n",
    "meanfi = mfi.mean(axis='columns')\n",
    "meanfi = pd.DataFrame(meanfi, columns=['mean'])\n",
    "data = pd.concat([mfi, meanfi], axis=1)\n",
    "data.index = 'age', 'female/male', 'right/left', 'OA', 'RA', 'history', 'bmi', 'hba1c', 'mua', 'logic/others', 'persona/others', 'optetrak/others','fine/others', 'cr/other', 'mpp/lpp', 'fta_pre', 'fta_po','flex_act_pre', 'flex_act_4w', 'flex_pas_pre', 'flex_pas_4w','ext_act_pre', 'ext_act_4w', 'ext_pas_pre', 'ext_pas_4w','gait_nor_pre', 'gait_nor_4w', 'gait_max_pre', 'gait_max_4w', 'joa_pre','joa_4w', 'α', 'β', 'θ', 'γ', 'JL_change'\n",
    "data.to_csv(\"C:/Users/user/feature_importance.csv\", encoding = 'shift-jis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
